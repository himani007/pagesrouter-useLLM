import { OpenAIMessage } from "./utils";
export interface CreateLLMServiceOptions {
    openaiApiKey?: string;
    elvenLabsApiKey?: string;
    actions?: string[];
    fetcher?: typeof fetch;
    templates?: {
        [id: string]: LLMServiceTemplate;
    };
    debug?: boolean;
    isAllowed?: (options: LLMServiceHandleOptions) => boolean | Promise<boolean>;
}
export interface LLMServiceTemplate {
    id: string;
    systemPrompt?: string;
    userPrompt?: string;
    model?: string;
    temperature?: number;
    top_p?: number;
    n?: number;
    max_tokens?: number;
    presence_penalty?: number;
    frequency_penalty?: number;
    logit_bias?: number;
}
export interface LLMServiceChatOptions {
    $action?: string;
    messages?: OpenAIMessage[];
    stream?: boolean;
    template?: string;
    inputs?: object;
    user?: string;
}
export interface LLMServiceTranscribeOptions {
    $action?: string;
    audioUrl?: string;
    language?: string;
    prompt?: string;
}
export interface LLMServiceEmbedOptions {
    $action?: string;
    input?: string | string[];
    user?: string;
    model?: string;
}
export interface LLMServiceHandleOptions {
    body: object;
    request?: Request;
}
export interface LLMServiceSpeakOptions {
    $action?: string;
    text?: string;
    model_id?: string;
    voice_id?: string;
    voice_settings?: {
        stability: number;
        similarity_boost: number;
    };
}
export interface LLMServiceGenerateImageOptions {
    $action?: string;
    prompt: string;
    n?: number;
    size?: string;
    response_format?: string;
    user?: string;
}
export interface LLMServiceEditImageOptions {
    $action?: string;
    image: string;
    mask?: string;
    prompt?: string;
    n?: number;
    size?: string;
    response_format?: string;
    user?: string;
}
export interface LLMServiceImageVariationOptions {
    $action?: string;
    image: string;
    n?: number;
    size?: string;
    response_format?: string;
    user?: string;
}
export interface LLMServiceHandleResponse {
    result: ReadableStream | string;
}
export declare class LLMService {
    templates: {
        [id: string]: LLMServiceTemplate;
    };
    openaiApiKey: string;
    elvenLabsApiKey: string;
    fetcher: typeof fetch;
    debug: boolean;
    actions: string[];
    isAllowed: (options: LLMServiceHandleOptions) => boolean | Promise<boolean>;
    constructor({ openaiApiKey, elvenLabsApiKey, fetcher, templates, debug, isAllowed, actions, }: CreateLLMServiceOptions);
    registerTemplate(template: LLMServiceTemplate): void;
    prepareChatBody(body: LLMServiceChatOptions): {
        messages: OpenAIMessage[];
        stream: boolean | undefined;
        user: string | undefined;
        model: string;
        temperature: number;
        top_p: number | undefined;
        n: number | undefined;
        max_tokens: number;
        presence_penalty: number | undefined;
        frequency_penalty: number | undefined;
        logit_bias: number | undefined;
    };
    handle({ body, request, }: LLMServiceHandleOptions): Promise<LLMServiceHandleResponse>;
    chat(body: LLMServiceChatOptions): Promise<LLMServiceHandleResponse>;
    embed(options: LLMServiceEmbedOptions): Promise<{
        result: string;
    }>;
    transcribe(options: LLMServiceTranscribeOptions): Promise<{
        result: string;
    }>;
    speak(options: LLMServiceSpeakOptions): Promise<{
        result: string;
    }>;
    generateImage(options: LLMServiceGenerateImageOptions): Promise<{
        result: string;
    }>;
    editImage(options: LLMServiceEditImageOptions): Promise<{
        result: string;
    }>;
    imageVariation(options: LLMServiceImageVariationOptions): Promise<{
        result: string;
    }>;
}
export default function createLLMService(options?: CreateLLMServiceOptions): LLMService;
